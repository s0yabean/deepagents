{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecc3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\", override=True)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c897bc9",
   "metadata": {},
   "source": [
    "# Deepagent for Research\n",
    "\n",
    "We will use the `deepagents` package to create a research agent. When using the `deepagents` package, it's important to: \n",
    "\n",
    "1. Understand the native tools available\n",
    "2. Supply task-specific tools\n",
    "3. Supply task-specific instructions\n",
    "4. Supply task-specific sub-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14c09e",
   "metadata": {},
   "source": [
    "## Task-Specific Tools \n",
    "\n",
    "You can see an overview of the native tools in the [deepagents package README](https://github.com/langchain-ai/deepagents?tab=readme-ov-file#model) as well as the [quickstarts README](https://github.com/langchain-ai/deepagents-quickstarts). We'll extend this with two task-specific tools. \n",
    "\n",
    "### Search Tool \n",
    "\n",
    "There are different search tools that we can use. For example, we can use [Tavily](https://www.tavily.com/) to search for relevant URLs, then fetches the full webpage content.\n",
    "\n",
    "### Think Tool \n",
    "\n",
    "We'll supply a [think tool](https://www.anthropic.com/engineering/claude-think-tool), which is a useful way to help audit agent decision making. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9163556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_agent.tools import tavily_search, think_tool\n",
    "tools = [tavily_search, think_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3ee5b",
   "metadata": {},
   "source": [
    "## Task-Specific Instructions\n",
    " \n",
    "Next, let's define task specific instructions using [a few prompting techniques for agents](https://youtu.be/XSZP9GhhuAc?si=zowpViL-2j-vI9hA):\n",
    "\n",
    "### 1. Think Like The Agent\n",
    "What instructions would you give a new work colleague?\n",
    "- **Read the question carefully** - What specific information does the user need?\n",
    "- **Start with broader searches** - Use broad, comprehensive queries first\n",
    "- **After each search, pause and assess** - Do I have enough to answer? What's still missing?\n",
    "- **Execute narrower searches as you gather information** - Fill in the gaps.\n",
    "\n",
    "### 2. Concrete Heuristics (Prevent \"Spin-Out\" on excessive tool calls)\n",
    "Use **Hard Limits** to prevent the research agent from calling tools excessively:\n",
    "- **Stop when you can answer confidently** - Don't keep searching for perfection.\n",
    "- **Give it budgets** - Use 2-3 search tool calls for simple queries. Use up to 5 for complex queries.\n",
    "- **Limit** - Always stop after 5 search tool calls if you cannot find the right source(s).\n",
    "\n",
    "### 3. Show your thinking\n",
    "After each search tool calling, use [`think_tool` to analyze the results](https://www.anthropic.com/engineering/claude-think-tool):\n",
    "- What key information did I find? \n",
    "- What's missing?\n",
    "- Do I have enough to answer the question comprehensively?\n",
    "- Should I search more or provide my answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4487f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_prompt, format_messages\n",
    "from research_agent.prompts import (\n",
    "    RESEARCHER_INSTRUCTIONS,\n",
    "    RESEARCH_WORKFLOW_INSTRUCTIONS,\n",
    "    SUBAGENT_DELEGATION_INSTRUCTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5eb7a89-8a26-4fb4-ba77-b05180f2c67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You are a research assistant conducting research on the user's input topic. For context, today's date is       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  {date}.                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Task&gt;</span>                                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Your job is to use tools to gather information about the user's input topic.                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You can use any of the research tools provided to you to find resources that can help answer the research      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  question.                                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You can call these tools in series or in parallel, your research is conducted in a tool-calling loop.          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Task&gt;</span>                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Available Research Tools&gt;</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You have access to two specific research tools:                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **tavily_search**: For conducting web searches to gather information                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **think_tool**: For reflection and strategic planning during research                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **CRITICAL: Use think_tool after each search to reflect on results and plan next steps**                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Available Research Tools&gt;</span>                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Instructions&gt;</span>                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Think like a human researcher with limited time. Follow these steps:                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Read the question carefully** - What specific information does the user need?                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Start with broader searches** - Use broad, comprehensive queries first                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. **After each search, pause and assess** - Do I have enough to answer? What's still missing?                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  4. **Execute narrower searches as you gather information** - Fill in the gaps                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  5. **Stop when you can answer confidently** - Don't keep searching for perfection                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Instructions&gt;</span>                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Hard Limits&gt;</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Tool Call Budgets** (Prevent excessive searching):                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Simple queries**: Use 2-3 search tool calls maximum                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Complex queries**: Use up to 5 search tool calls maximum                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Always stop**: After 5 search tool calls if you cannot find the right sources                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Stop Immediately When**:                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - You can answer the user's question comprehensively                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - You have 3+ relevant examples/sources for the question                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Your last 2 searches returned similar information                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Hard Limits&gt;</span>                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Show Your Thinking&gt;</span>                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  After each search tool call, use think_tool to analyze the results:                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - What key information did I find?                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - What's missing?                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Do I have enough to answer the question comprehensively?                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Should I search more or provide my answer?                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Show Your Thinking&gt;</span>                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Final Response Format&gt;</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  When providing your final answer, use numbered citations and include a Sources section:                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Cite sources inline**: Use [1], [2], [3] format when referencing information                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Sources section**: End with a numbered list of all sources                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Example format:                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context engineering is a critical technique for AI agents [1]. Studies show that proper context management     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  can improve performance by 40% [2].                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Sources</span>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [1] Context Engineering Guide: https://example.com/context-guide                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [2] AI Performance Study: https://example.com/study                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  This allows readers to verify information and explore topics further.                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Final Response Format&gt;</span>                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You are a research assistant conducting research on the user's input topic. For context, today's date is       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  {date}.                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Task>\u001b[0m                                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Your job is to use tools to gather information about the user's input topic.                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You can use any of the research tools provided to you to find resources that can help answer the research      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  question.                                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You can call these tools in series or in parallel, your research is conducted in a tool-calling loop.          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Task>\u001b[0m                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Available Research Tools>\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You have access to two specific research tools:                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **tavily_search**: For conducting web searches to gather information                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **think_tool**: For reflection and strategic planning during research                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **CRITICAL: Use think_tool after each search to reflect on results and plan next steps**                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Available Research Tools>\u001b[0m                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Instructions>\u001b[0m                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Think like a human researcher with limited time. Follow these steps:                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Read the question carefully** - What specific information does the user need?                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Start with broader searches** - Use broad, comprehensive queries first                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. **After each search, pause and assess** - Do I have enough to answer? What's still missing?                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  4. **Execute narrower searches as you gather information** - Fill in the gaps                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  5. **Stop when you can answer confidently** - Don't keep searching for perfection                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Instructions>\u001b[0m                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Hard Limits>\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Tool Call Budgets** (Prevent excessive searching):                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Simple queries**: Use 2-3 search tool calls maximum                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Complex queries**: Use up to 5 search tool calls maximum                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Always stop**: After 5 search tool calls if you cannot find the right sources                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Stop Immediately When**:                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - You can answer the user's question comprehensively                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - You have 3+ relevant examples/sources for the question                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Your last 2 searches returned similar information                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Hard Limits>\u001b[0m                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Show Your Thinking>\u001b[0m                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  After each search tool call, use think_tool to analyze the results:                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - What key information did I find?                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - What's missing?                                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Do I have enough to answer the question comprehensively?                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Should I search more or provide my answer?                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Show Your Thinking>\u001b[0m                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Final Response Format>\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  When providing your final answer, use numbered citations and include a Sources section:                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Cite sources inline**: Use [1], [2], [3] format when referencing information                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Sources section**: End with a numbered list of all sources                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Example format:                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context engineering is a critical technique for AI agents [1]. Studies show that proper context management     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  can improve performance by 40% [2].                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Sources\u001b[0m                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [1] Context Engineering Guide: https://example.com/context-guide                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [2] AI Performance Study: https://example.com/study                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  This allows readers to verify information and explore topics further.                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Final Response Format>\u001b[0m                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_prompt(RESEARCHER_INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab6e7e",
   "metadata": {},
   "source": [
    "## Task-Specific Sub-Agents\n",
    "\n",
    "You can specify [custom subagents](https://github.com/langchain-ai/deepagents?tab=readme-ov-file#subagents) as a means of context isolation. \n",
    "\n",
    "Here's well define a sub-agent that can search the web for information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6570183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create research sub-agent\n",
    "research_sub_agent = {\n",
    "    \"name\": \"research-agent\",\n",
    "    \"description\": \"Delegate research to the sub-agent researcher. Only give this researcher one topic at a time.\",\n",
    "    \"system_prompt\": RESEARCHER_INSTRUCTIONS,\n",
    "    \"tools\": [tavily_search, think_tool],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef99f1d",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Now, we can look at all of our instructions together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e55b2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  # Research Workflow                                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Follow this workflow for all research requests:                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Save the request**: Use write_file() to save the user's research question to `/research_request.md`       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Plan**: Create a todo list with write_todos to break down the research into focused tasks                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. **Research**: Delegate research tasks to sub-agents using the task() tool                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  4. **Write Report**: Write a comprehensive final report to `/final_report.md` (see Report Writing Guidelines   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  below)                                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  5. **Verify**: Read `/research_request.md` to confirm you've addressed all aspects of the original question    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Research Planning Guidelines</span>                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Batch similar research tasks into a single TODO to minimize overhead                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - For simple fact-finding questions, use 1 sub-agent                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - For comparisons or multi-faceted topics, delegate to multiple parallel sub-agents                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Each sub-agent should research one specific aspect and return findings                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Report Writing Guidelines</span>                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  When writing the final report to `/final_report.md`, follow these structure patterns:                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **For comparisons:**                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. Introduction                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. Overview of topic A                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. Overview of topic B                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  4. Detailed comparison                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  5. Conclusion                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **For lists/rankings:**                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Simply list items with details - no introduction needed:                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. Item 1 with explanation                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. Item 2 with explanation                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. Item 3 with explanation                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **For summaries/overviews:**                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. Overview of topic                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. Key concept 1                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. Key concept 2                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  4. Key concept 3                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  5. Conclusion                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **General guidelines:**                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Use clear section headings (<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## for sections, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### for subsections)</span>                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Write in paragraph form by default - be text-heavy, not just bullet points                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Do NOT use self-referential language (\"I found...\", \"I researched...\")                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Write as a professional report without meta-commentary                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Each section should be comprehensive and detailed                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Use bullet points only when listing is more appropriate than prose                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Citation Rules&gt;</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Use numbered citations throughout your report:                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Cite sources inline using [1], [2], [3] format                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Assign each unique URL a single citation number                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - End report with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Sources section listing each numbered source</span>                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Number sources sequentially without gaps (1,2,3,4...)                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Format: [1] Source Title: URL (each on separate line for proper list rendering)                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Example:                                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>    Some important finding [1]. Another key insight [2].                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Sources</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>    [1] AI Research Paper: https://example.com/paper                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>    [2] Industry Analysis: https://example.com/analysis                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Citation Rules&gt;</span>                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ================================================================================                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  # Sub-Agent Research Coordination                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Your role is to coordinate research by delegating tasks from your TODO list to specialized research            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  sub-agents.                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Delegation Strategy</span>                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Simple queries** → 1 sub-agent:                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"List the top 10 coffee shops in San Francisco\"                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"What is quantum computing?\"                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"Summarize the history of the internet\"                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Comparisons** → 1 sub-agent per element:                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"Compare OpenAI vs Anthropic vs DeepMind AI safety approaches\" → 3 parallel sub-agents                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"Compare Python vs JavaScript for web development\" → 2 parallel sub-agents                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Multi-faceted research** → 1 sub-agent per aspect:                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"Research renewable energy: costs, environmental impact, adoption rates\" → 3 parallel sub-agents             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"Analyze the 2024 election: candidates, issues, polling\" → 3 parallel sub-agents                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Parallel Execution</span>                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Use at most {max_concurrent_research_units} parallel sub-agents per iteration                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Make multiple task() calls in a single response to enable parallel execution                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Each sub-agent returns findings independently                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Research Limits</span>                                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Stop after {max_researcher_iterations} delegation rounds if you haven't found adequate sources               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Stop when you have sufficient information to answer comprehensively                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Bias towards focused research over exhaustive exploration                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ================================================================================                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You are a research assistant conducting research on the user's input topic. For context, today's date is       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  {date}.                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Task&gt;</span>                                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Your job is to use tools to gather information about the user's input topic.                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You can use any of the research tools provided to you to find resources that can help answer the research      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  question.                                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You can call these tools in series or in parallel, your research is conducted in a tool-calling loop.          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Task&gt;</span>                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Available Research Tools&gt;</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You have access to two specific research tools:                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **tavily_search**: For conducting web searches to gather information                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **think_tool**: For reflection and strategic planning during research                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **CRITICAL: Use think_tool after each search to reflect on results and plan next steps**                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Available Research Tools&gt;</span>                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Instructions&gt;</span>                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Think like a human researcher with limited time. Follow these steps:                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Read the question carefully** - What specific information does the user need?                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Start with broader searches** - Use broad, comprehensive queries first                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. **After each search, pause and assess** - Do I have enough to answer? What's still missing?                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  4. **Execute narrower searches as you gather information** - Fill in the gaps                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  5. **Stop when you can answer confidently** - Don't keep searching for perfection                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Instructions&gt;</span>                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Hard Limits&gt;</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Tool Call Budgets** (Prevent excessive searching):                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Simple queries**: Use 2-3 search tool calls maximum                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Complex queries**: Use up to 5 search tool calls maximum                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Always stop**: After 5 search tool calls if you cannot find the right sources                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Stop Immediately When**:                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - You can answer the user's question comprehensively                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - You have 3+ relevant examples/sources for the question                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Your last 2 searches returned similar information                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Hard Limits&gt;</span>                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Show Your Thinking&gt;</span>                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  After each search tool call, use think_tool to analyze the results:                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - What key information did I find?                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - What's missing?                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Do I have enough to answer the question comprehensively?                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Should I search more or provide my answer?                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Show Your Thinking&gt;</span>                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Final Response Format&gt;</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  When providing your final answer, use numbered citations and include a Sources section:                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Cite sources inline**: Use [1], [2], [3] format when referencing information                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Sources section**: End with a numbered list of all sources                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Example format:                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context engineering is a critical technique for AI agents [1]. Studies show that proper context management     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  can improve performance by 40% [2].                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Sources</span>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [1] Context Engineering Guide: https://example.com/context-guide                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [2] AI Performance Study: https://example.com/study                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  This allows readers to verify information and explore topics further.                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Final Response Format&gt;</span>                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  # Research Workflow                                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Follow this workflow for all research requests:                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Save the request**: Use write_file() to save the user's research question to `/research_request.md`       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Plan**: Create a todo list with write_todos to break down the research into focused tasks                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. **Research**: Delegate research tasks to sub-agents using the task() tool                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  4. **Write Report**: Write a comprehensive final report to `/final_report.md` (see Report Writing Guidelines   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  below)                                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  5. **Verify**: Read `/research_request.md` to confirm you've addressed all aspects of the original question    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Research Planning Guidelines\u001b[0m                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Batch similar research tasks into a single TODO to minimize overhead                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - For simple fact-finding questions, use 1 sub-agent                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - For comparisons or multi-faceted topics, delegate to multiple parallel sub-agents                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Each sub-agent should research one specific aspect and return findings                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Report Writing Guidelines\u001b[0m                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  When writing the final report to `/final_report.md`, follow these structure patterns:                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **For comparisons:**                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. Introduction                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. Overview of topic A                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. Overview of topic B                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  4. Detailed comparison                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  5. Conclusion                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **For lists/rankings:**                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Simply list items with details - no introduction needed:                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. Item 1 with explanation                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. Item 2 with explanation                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. Item 3 with explanation                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **For summaries/overviews:**                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. Overview of topic                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. Key concept 1                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. Key concept 2                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  4. Key concept 3                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  5. Conclusion                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **General guidelines:**                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Use clear section headings (\u001b[1;35m## for sections, \u001b[0m\u001b[1;36m#\u001b[0m\u001b[1;36m## for subsections)\u001b[0m                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Write in paragraph form by default - be text-heavy, not just bullet points                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Do NOT use self-referential language (\"I found...\", \"I researched...\")                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Write as a professional report without meta-commentary                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Each section should be comprehensive and detailed                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Use bullet points only when listing is more appropriate than prose                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Citation Rules>\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Use numbered citations throughout your report:                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Cite sources inline using [1], [2], [3] format                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Assign each unique URL a single citation number                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - End report with \u001b[1;36m#\u001b[0m\u001b[1;36m## Sources section listing each numbered source\u001b[0m                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Number sources sequentially without gaps (1,2,3,4...)                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Format: [1] Source Title: URL (each on separate line for proper list rendering)                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Example:                                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m    Some important finding [1]. Another key insight [2].                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m    \u001b[1;36m#\u001b[0m\u001b[1;36m## Sources\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m    [1] AI Research Paper: https://example.com/paper                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m    [2] Industry Analysis: https://example.com/analysis                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Citation Rules>\u001b[0m                                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ================================================================================                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  # Sub-Agent Research Coordination                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Your role is to coordinate research by delegating tasks from your TODO list to specialized research            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  sub-agents.                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Delegation Strategy\u001b[0m                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Simple queries** → 1 sub-agent:                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"List the top 10 coffee shops in San Francisco\"                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"What is quantum computing?\"                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"Summarize the history of the internet\"                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Comparisons** → 1 sub-agent per element:                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"Compare OpenAI vs Anthropic vs DeepMind AI safety approaches\" → 3 parallel sub-agents                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"Compare Python vs JavaScript for web development\" → 2 parallel sub-agents                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Multi-faceted research** → 1 sub-agent per aspect:                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"Research renewable energy: costs, environmental impact, adoption rates\" → 3 parallel sub-agents             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"Analyze the 2024 election: candidates, issues, polling\" → 3 parallel sub-agents                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Parallel Execution\u001b[0m                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Use at most {max_concurrent_research_units} parallel sub-agents per iteration                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Make multiple task() calls in a single response to enable parallel execution                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Each sub-agent returns findings independently                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Research Limits\u001b[0m                                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Stop after {max_researcher_iterations} delegation rounds if you haven't found adequate sources               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Stop when you have sufficient information to answer comprehensively                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Bias towards focused research over exhaustive exploration                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ================================================================================                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You are a research assistant conducting research on the user's input topic. For context, today's date is       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  {date}.                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Task>\u001b[0m                                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Your job is to use tools to gather information about the user's input topic.                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You can use any of the research tools provided to you to find resources that can help answer the research      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  question.                                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You can call these tools in series or in parallel, your research is conducted in a tool-calling loop.          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Task>\u001b[0m                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Available Research Tools>\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You have access to two specific research tools:                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **tavily_search**: For conducting web searches to gather information                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **think_tool**: For reflection and strategic planning during research                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **CRITICAL: Use think_tool after each search to reflect on results and plan next steps**                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Available Research Tools>\u001b[0m                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Instructions>\u001b[0m                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Think like a human researcher with limited time. Follow these steps:                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Read the question carefully** - What specific information does the user need?                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Start with broader searches** - Use broad, comprehensive queries first                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. **After each search, pause and assess** - Do I have enough to answer? What's still missing?                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  4. **Execute narrower searches as you gather information** - Fill in the gaps                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  5. **Stop when you can answer confidently** - Don't keep searching for perfection                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Instructions>\u001b[0m                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Hard Limits>\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Tool Call Budgets** (Prevent excessive searching):                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Simple queries**: Use 2-3 search tool calls maximum                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Complex queries**: Use up to 5 search tool calls maximum                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Always stop**: After 5 search tool calls if you cannot find the right sources                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Stop Immediately When**:                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - You can answer the user's question comprehensively                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - You have 3+ relevant examples/sources for the question                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Your last 2 searches returned similar information                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Hard Limits>\u001b[0m                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Show Your Thinking>\u001b[0m                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  After each search tool call, use think_tool to analyze the results:                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - What key information did I find?                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - What's missing?                                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Do I have enough to answer the question comprehensively?                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Should I search more or provide my answer?                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Show Your Thinking>\u001b[0m                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Final Response Format>\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  When providing your final answer, use numbered citations and include a Sources section:                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Cite sources inline**: Use [1], [2], [3] format when referencing information                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Sources section**: End with a numbered list of all sources                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Example format:                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context engineering is a critical technique for AI agents [1]. Studies show that proper context management     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  can improve performance by 40% [2].                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Sources\u001b[0m                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [1] Context Engineering Guide: https://example.com/context-guide                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [2] AI Performance Study: https://example.com/study                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  This allows readers to verify information and explore topics further.                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Final Response Format>\u001b[0m                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INSTRUCTIONS = (\n",
    "    RESEARCH_WORKFLOW_INSTRUCTIONS\n",
    "    + \"\\n\\n\"\n",
    "    + \"=\" * 80\n",
    "    + \"\\n\\n\"\n",
    "    + SUBAGENT_DELEGATION_INSTRUCTIONS\n",
    "    + \"\\n\\n\"\n",
    "    + \"=\" * 80\n",
    "    + \"\\n\\n\"\n",
    "    + RESEARCHER_INSTRUCTIONS\n",
    ")\n",
    "\n",
    "show_prompt(INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e3639",
   "metadata": {},
   "source": [
    "### Create the agent\n",
    "\n",
    "Now, we create our deepagent with these components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e979ff23-e36a-45b2-bd52-03cf4171f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from deepagents import create_deep_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Model Claude 4.5\n",
    "model = init_chat_model(model=\"anthropic:claude-sonnet-4-5-20250929\", temperature=0.0)\n",
    "\n",
    "# Model Gemini 3 \n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-3-pro-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62da8411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the agent\n",
    "agent = create_deep_agent(\n",
    "      model=model,\n",
    "      tools=tools, \n",
    "      system_prompt=INSTRUCTIONS,\n",
    "      subagents=[research_sub_agent],\n",
    "  )\n",
    "  \n",
    "# Show the agent\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "613634c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────────── 🧑 Human ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> research context engineering approaches used to build AI agents                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────────────\u001b[0m\u001b[34m 🧑 Human \u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m research context engineering approaches used to build AI agents                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: write_file                                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"content\": \"research context engineering approaches used to build AI agents\",                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"file_path\": \"/research_request.md\"                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: a4a0832d-9bae-487c-b52f-164d0b47afdc                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: write_todos                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"todos\": [                                                                                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research core concepts and definitions of context engineering in AI agents\",                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"in_progress\"                                                                                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research structural techniques for context management (e.g., RAG, Long-term memory systems,   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Sliding windows)\",                                                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"pending\"                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research context optimization and compression techniques (e.g., Prompt compression,           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Summarization, Token selection)\",                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"pending\"                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Write final report on context engineering approaches\",                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"pending\"                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     }                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   ]                                                                                                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: 29e25aca-85a1-41f9-9149-4304f30e5fa5                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: write_file                                                                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"content\": \"research context engineering approaches used to build AI agents\",                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"file_path\": \"/research_request.md\"                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: a4a0832d-9bae-487c-b52f-164d0b47afdc                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: write_todos                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"todos\": [                                                                                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research core concepts and definitions of context engineering in AI agents\",                  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"in_progress\"                                                                                   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research structural techniques for context management (e.g., RAG, Long-term memory systems,   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Sliding windows)\",                                                                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"pending\"                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research context optimization and compression techniques (e.g., Prompt compression,           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Summarization, Token selection)\",                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"pending\"                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Write final report on context engineering approaches\",                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"pending\"                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     }                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   ]                                                                                                             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: 29e25aca-85a1-41f9-9149-4304f30e5fa5                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Updated file /research_request.md                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Updated file /research_request.md                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Updated todo list to [{'content': 'Research core concepts and definitions of context engineering in AI agents', <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 'status': 'in_progress'}, {'content': 'Research structural techniques for context management (e.g., RAG,        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Long-term memory systems, Sliding windows)', 'status': 'pending'}, {'content': 'Research context optimization   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> and compression techniques (e.g., Prompt compression, Summarization, Token selection)', 'status': 'pending'},   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> {'content': 'Write final report on context engineering approaches', 'status': 'pending'}]                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Updated todo list to [{'content': 'Research core concepts and definitions of context engineering in AI agents', \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 'status': 'in_progress'}, {'content': 'Research structural techniques for context management (e.g., RAG,        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Long-term memory systems, Sliding windows)', 'status': 'pending'}, {'content': 'Research context optimization   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m and compression techniques (e.g., Prompt compression, Summarization, Token selection)', 'status': 'pending'},   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m {'content': 'Write final report on context engineering approaches', 'status': 'pending'}]                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: task                                                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"subagent_type\": \"research-agent\",                                                                            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"description\": \"Research the core concepts and definitions of 'context engineering' specifically for AI       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> agents. \\nFind out:\\n1. What is context engineering?\\n2. Why is it critical for AI agents?\\n3. Key principles   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> (e.g. relevance, coherence, token limits).\\n4. Distinctions between context engineering and prompt              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> engineering.\\n\\nReturn a summary of findings with sources.\"                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: 60ae692d-a760-4254-8819-d3541d2b6456                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: task                                                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"subagent_type\": \"research-agent\",                                                                            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"description\": \"Research structural techniques for context management in AI agents.\\nFocus on:\\n1.            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Retrieval-Augmented Generation (RAG) patterns for context injection.\\n2. Memory architectures (Short-term vs    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Long-term, Vector databases).\\n3. Context window management strategies (Sliding windows, Hierarchical           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context).\\n4. Dynamic context selection methods.\\n\\nReturn a summary of findings with sources.\"                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: 8ce46bb7-c73d-47ff-a20d-ff7add14a95a                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: task                                                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"subagent_type\": \"research-agent\",                                                                            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"description\": \"Research context optimization and compression techniques for AI agents.\\nFocus on:\\n1.        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Summarization techniques to reduce context size.\\n2. Prompt compression algorithms (e.g., selective context,    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> LLMLingua).\\n3. Token selection/pruning strategies.\\n4. Any specific tools or libraries known for this (e.g.    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> LangChain's approaches).\\n\\nReturn a summary of findings with sources.\"                                         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: ae5f9ef0-1ebb-48dc-ae07-438f9205f022                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: task                                                                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"subagent_type\": \"research-agent\",                                                                            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"description\": \"Research the core concepts and definitions of 'context engineering' specifically for AI       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m agents. \\nFind out:\\n1. What is context engineering?\\n2. Why is it critical for AI agents?\\n3. Key principles   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m (e.g. relevance, coherence, token limits).\\n4. Distinctions between context engineering and prompt              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m engineering.\\n\\nReturn a summary of findings with sources.\"                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: 60ae692d-a760-4254-8819-d3541d2b6456                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: task                                                                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"subagent_type\": \"research-agent\",                                                                            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"description\": \"Research structural techniques for context management in AI agents.\\nFocus on:\\n1.            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Retrieval-Augmented Generation (RAG) patterns for context injection.\\n2. Memory architectures (Short-term vs    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Long-term, Vector databases).\\n3. Context window management strategies (Sliding windows, Hierarchical           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context).\\n4. Dynamic context selection methods.\\n\\nReturn a summary of findings with sources.\"                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: 8ce46bb7-c73d-47ff-a20d-ff7add14a95a                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: task                                                                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"subagent_type\": \"research-agent\",                                                                            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"description\": \"Research context optimization and compression techniques for AI agents.\\nFocus on:\\n1.        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Summarization techniques to reduce context size.\\n2. Prompt compression algorithms (e.g., selective context,    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m LLMLingua).\\n3. Token selection/pruning strategies.\\n4. Any specific tools or libraries known for this (e.g.    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m LangChain's approaches).\\n\\nReturn a summary of findings with sources.\"                                         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: ae5f9ef0-1ebb-48dc-ae07-438f9205f022                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Based on the research, here is a summary of the core concepts of **Context Engineering** for AI agents.         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 1. What is Context Engineering?                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Context Engineering** is the technical practice of designing, curating, and managing the total information    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> state (the \"context\") provided to an AI agent during its operation. Unlike simple prompting, which focuses on a <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> single input instruction, context engineering is a **systemic and iterative process** that determines *what*    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> information an agent perceives at every step of a workflow [1].                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> It involves configuring the optimal set of tokens—including system instructions, tool definitions, conversation <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> history, and external data—to ensure the model behaves reliably over time. Ideally, it answers the question:    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *\"What configuration of context is most likely to generate the model's desired behavior?\"* [2]                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 2. Why is it Critical for AI Agents?                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Context engineering is essential for shifting from simple chatbots to autonomous agents that perform complex,   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> multi-step tasks.                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Combating \"Context Rot\":** As the amount of information (tokens) in a context window increases, a model’s <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ability to retrieve specific details (\"needle-in-a-haystack\") often degrades. This is due to the **attention    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> scarcity** inherent in transformer architectures (where computational complexity is $N^2$ relative to context   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> length) [1].                                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Enabling Long-Horizon Tasks:** Agents working on tasks spanning hours or days (e.g., coding, research)    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> accumulate massive amounts of history. Without engineering strategies to manage this, the context window fills  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> up, leading to lost instructions, confusion, or crashed sessions [1].                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Reliability &amp; Cost:** Providing \"just enough\" high-signal context reduces hallucination risks and         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> operational costs associated with processing unnecessary tokens.                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 3. Key Principles of Context Engineering                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Effective context engineering relies on providing the **smallest possible set of high-signal tokens**.          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Relevance (Signal-to-Noise Ratio):**                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     *   **Just-in-Time Retrieval:** Instead of dumping all files into the context (traditional RAG), agents     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> should be equipped with tools (like `grep` or `ls`) to autonomously \"pull\" only the information they need when  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> they need it [2].                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     *   **The \"Right Altitude\":** System prompts should avoid being too brittle (hardcoded logic) or too vague. <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> They should provide flexible heuristics and distinct sections (e.g., Background, Tools, Output Format).         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Coherence &amp; State Management:**                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     *   **Compaction:** Periodically summarizing conversation history to compress the context while preserving  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> critical decisions and unresolved issues [1].                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     *   **Structured Note-Taking:** Forcing agents to maintain persistent \"memory files\" (e.g., `scratchpad.md` <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> or `todo.md`) outside the context window to track progress across resets.                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Token Efficiency:**                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     *   **Tool Optimization:** Tool definitions should be concise. If a human engineer cannot determine which   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> tool to use based on the definition, the agent won't be able to either. Return values from tools should be      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> stripped of extraneous data to save space [2].                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 4. Context Engineering vs. Prompt Engineering                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> While prompt engineering is about *crafting the message*, context engineering is about *architecting the        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> environment*.                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | Feature | Prompt Engineering | Context Engineering |                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | :--- | :--- | :--- |                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | **Scope** | Discrete, single-turn interactions. | Continuous, multi-turn workflows and system state. |        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | **Focus** | Finding the \"right words\" or instructions. | Curating the \"optimal set of tokens\" (history,       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> tools, data). |                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | **Goal** | Optimizing a specific response. | Maintaining agent reliability and state over time. |             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | **Mechanism** | Static text input. | Dynamic management (retrieval, summarization, pruning). |                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | **Analogy** | Writing a good email to an employee. | Designing the employee's office, filing system, and      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> handbook. |                                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Sources                                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [1] HowAIWorks.ai, \"Context Engineering: AI Agent Optimization Guide,\" Oct 2025.                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [2] Anthropic Engineering, \"Effective context engineering for AI agents\" (referenced within [1]).               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Based on the research, here is a summary of the core concepts of **Context Engineering** for AI agents.         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 1. What is Context Engineering?                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Context Engineering** is the technical practice of designing, curating, and managing the total information    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m state (the \"context\") provided to an AI agent during its operation. Unlike simple prompting, which focuses on a \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m single input instruction, context engineering is a **systemic and iterative process** that determines *what*    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m information an agent perceives at every step of a workflow [1].                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m It involves configuring the optimal set of tokens—including system instructions, tool definitions, conversation \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m history, and external data—to ensure the model behaves reliably over time. Ideally, it answers the question:    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *\"What configuration of context is most likely to generate the model's desired behavior?\"* [2]                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 2. Why is it Critical for AI Agents?                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Context engineering is essential for shifting from simple chatbots to autonomous agents that perform complex,   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m multi-step tasks.                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Combating \"Context Rot\":** As the amount of information (tokens) in a context window increases, a model’s \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ability to retrieve specific details (\"needle-in-a-haystack\") often degrades. This is due to the **attention    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m scarcity** inherent in transformer architectures (where computational complexity is $N^2$ relative to context   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m length) [1].                                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Enabling Long-Horizon Tasks:** Agents working on tasks spanning hours or days (e.g., coding, research)    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m accumulate massive amounts of history. Without engineering strategies to manage this, the context window fills  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m up, leading to lost instructions, confusion, or crashed sessions [1].                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Reliability & Cost:** Providing \"just enough\" high-signal context reduces hallucination risks and         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m operational costs associated with processing unnecessary tokens.                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 3. Key Principles of Context Engineering                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Effective context engineering relies on providing the **smallest possible set of high-signal tokens**.          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Relevance (Signal-to-Noise Ratio):**                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     *   **Just-in-Time Retrieval:** Instead of dumping all files into the context (traditional RAG), agents     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m should be equipped with tools (like `grep` or `ls`) to autonomously \"pull\" only the information they need when  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m they need it [2].                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     *   **The \"Right Altitude\":** System prompts should avoid being too brittle (hardcoded logic) or too vague. \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m They should provide flexible heuristics and distinct sections (e.g., Background, Tools, Output Format).         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Coherence & State Management:**                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     *   **Compaction:** Periodically summarizing conversation history to compress the context while preserving  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m critical decisions and unresolved issues [1].                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     *   **Structured Note-Taking:** Forcing agents to maintain persistent \"memory files\" (e.g., `scratchpad.md` \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m or `todo.md`) outside the context window to track progress across resets.                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Token Efficiency:**                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     *   **Tool Optimization:** Tool definitions should be concise. If a human engineer cannot determine which   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m tool to use based on the definition, the agent won't be able to either. Return values from tools should be      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m stripped of extraneous data to save space [2].                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 4. Context Engineering vs. Prompt Engineering                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m While prompt engineering is about *crafting the message*, context engineering is about *architecting the        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m environment*.                                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | Feature | Prompt Engineering | Context Engineering |                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | :--- | :--- | :--- |                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | **Scope** | Discrete, single-turn interactions. | Continuous, multi-turn workflows and system state. |        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | **Focus** | Finding the \"right words\" or instructions. | Curating the \"optimal set of tokens\" (history,       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m tools, data). |                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | **Goal** | Optimizing a specific response. | Maintaining agent reliability and state over time. |             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | **Mechanism** | Static text input. | Dynamic management (retrieval, summarization, pruning). |                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | **Analogy** | Writing a good email to an employee. | Designing the employee's office, filing system, and      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m handbook. |                                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Sources                                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [1] HowAIWorks.ai, \"Context Engineering: AI Agent Optimization Guide,\" Oct 2025.                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [2] Anthropic Engineering, \"Effective context engineering for AI agents\" (referenced within [1]).               \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Research into structural techniques for context management in AI agents reveals a shift from static retrieval   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> to dynamic, modular architectures that mimic human cognitive processes.                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 1. Retrieval-Augmented Generation (RAG) Patterns                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Modern RAG has evolved beyond simple vector search into **Modular RAG** architectures [1].                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Pre-Retrieval**: Techniques include **Query Rewriting** (transforming user input into optimal search      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> queries) and **Query Expansion** (generating multiple sub-queries to broaden search coverage).                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Post-Retrieval**: Retrieved contexts undergo **Re-ranking** (scoring by relevance) and **Pruning**        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> (removing redundant information) before reaching the LLM.                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **GraphRAG**: A structural technique that builds a knowledge graph from the corpus. It uses community       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> detection to create hierarchical summaries, allowing the agent to answer \"global\" questions (e.g., \"What are    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> the main themes?\") that standard vector search misses [2].                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Agentic RAG**: Treats retrieval as a multi-step reasoning process where an agent actively critiques       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> retrieved data and iteratively queries until it has sufficient context [1].                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 2. Memory Architectures                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Agent memory is structurally divided to balance immediate reasoning with long-term retention [3].               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Short-Term Memory (STM)**: Resides in the LLM's **context window**. It acts as a \"working memory\" for the <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> current session, often managed by summary buffers to prevent overflow.                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Long-Term Memory (LTM)**: Implemented via **Vector Databases** (for semantic search) and **Knowledge      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Graphs** (for structured relationships).                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Episodic Memory**: Stores specific past experiences (sequences of actions/results) to enable few-shot     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> learning from history.                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Procedural Memory**: Stores \"skills\" or \"how-to\" knowledge, often encoded as static prompt libraries or   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> code tools the agent can invoke.                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **MemGPT Pattern**: An architecture where the LLM acts as an operating system, autonomously managing its    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> own memory by deciding when to move information between context (STM) and storage (LTM) [3].                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 3. Context Window Management Strategies                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Techniques to maximize the utility of limited context windows include:                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Sliding Windows**: A standard technique where long documents are broken into overlapping chunks (e.g.,    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 512 tokens with 128-token overlap) to ensure no context is lost at boundaries during processing [4].            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Hierarchical Context**: Strategies like **GraphRAG** or **Fusion-in-Decoder (FiD)** process information   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> at multiple levels of abstraction. Documents are first summarized into high-level vectors; only relevant        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> sections are expanded into full text [2, 4].                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Compression**: summarizing or embedding retrieved chunks into dense vectors before they enter the main    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> context, allowing the agent to \"see\" more documents at lower resolution.                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 4. Dynamic Context Selection Methods                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Selecting the *right* context is as critical as retrieving it.                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Re-ranking Algorithms**: **Cross-Encoders** (e.g., BERT-based) score the semantic similarity between a    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> query and a document more accurately than bi-encoders but are computationally expensive. A common pattern is to <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> retrieve 100 documents with fast vector search, then re-rank the top 10 with a cross-encoder [5].               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Semantic Routing**: Using a lightweight classifier to direct queries to the most appropriate specialized  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> index or RAG pipeline (e.g., routing technical queries to a documentation index vs. billing queries to a SQL    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> database).                                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Stochastic &amp; Fairness Rankers**: New methods introduce \"stochastic rankers\" to prevent exposure bias      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> (where only the most popular docs are ever seen) and ensure diversity in the retrieved context [5].             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Sources                                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [1] Advanced &amp; Modular RAG Patterns: https://ai-radar.aoe.com/architecture-pattern/rag/                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [2] GraphRAG Overview: https://microsoft.github.io/graphrag/                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [3] Agent Memory Systems (STM/LTM/Episodic):                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://www.linkedin.com/pulse/day-4-agent-memory-systems-short-term-long-term-episodic-marques-rp3ge           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [4] LLM Input Formatting &amp; Sliding Windows:                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://milvus.io/ai-quick-reference/what-modifications-might-be-needed-to-the-llms-input-formatting-or-archite <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> cture-to-best-take-advantage-of-retrieved-documents-for-example-adding-special-tokens-or-segments-to-separate-c <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ontext                                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [5] Re-ranking &amp; Dynamic Selection:                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://www.chitika.com/re-ranking-in-retrieval-augmented-generation-how-to-use-re-rankers-in-rag/              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Research into structural techniques for context management in AI agents reveals a shift from static retrieval   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m to dynamic, modular architectures that mimic human cognitive processes.                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 1. Retrieval-Augmented Generation (RAG) Patterns                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Modern RAG has evolved beyond simple vector search into **Modular RAG** architectures [1].                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Pre-Retrieval**: Techniques include **Query Rewriting** (transforming user input into optimal search      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m queries) and **Query Expansion** (generating multiple sub-queries to broaden search coverage).                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Post-Retrieval**: Retrieved contexts undergo **Re-ranking** (scoring by relevance) and **Pruning**        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m (removing redundant information) before reaching the LLM.                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **GraphRAG**: A structural technique that builds a knowledge graph from the corpus. It uses community       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m detection to create hierarchical summaries, allowing the agent to answer \"global\" questions (e.g., \"What are    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m the main themes?\") that standard vector search misses [2].                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Agentic RAG**: Treats retrieval as a multi-step reasoning process where an agent actively critiques       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m retrieved data and iteratively queries until it has sufficient context [1].                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 2. Memory Architectures                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Agent memory is structurally divided to balance immediate reasoning with long-term retention [3].               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Short-Term Memory (STM)**: Resides in the LLM's **context window**. It acts as a \"working memory\" for the \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m current session, often managed by summary buffers to prevent overflow.                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Long-Term Memory (LTM)**: Implemented via **Vector Databases** (for semantic search) and **Knowledge      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Graphs** (for structured relationships).                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Episodic Memory**: Stores specific past experiences (sequences of actions/results) to enable few-shot     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m learning from history.                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Procedural Memory**: Stores \"skills\" or \"how-to\" knowledge, often encoded as static prompt libraries or   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m code tools the agent can invoke.                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **MemGPT Pattern**: An architecture where the LLM acts as an operating system, autonomously managing its    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m own memory by deciding when to move information between context (STM) and storage (LTM) [3].                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 3. Context Window Management Strategies                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Techniques to maximize the utility of limited context windows include:                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Sliding Windows**: A standard technique where long documents are broken into overlapping chunks (e.g.,    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 512 tokens with 128-token overlap) to ensure no context is lost at boundaries during processing [4].            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Hierarchical Context**: Strategies like **GraphRAG** or **Fusion-in-Decoder (FiD)** process information   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m at multiple levels of abstraction. Documents are first summarized into high-level vectors; only relevant        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m sections are expanded into full text [2, 4].                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Compression**: summarizing or embedding retrieved chunks into dense vectors before they enter the main    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m context, allowing the agent to \"see\" more documents at lower resolution.                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 4. Dynamic Context Selection Methods                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Selecting the *right* context is as critical as retrieving it.                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Re-ranking Algorithms**: **Cross-Encoders** (e.g., BERT-based) score the semantic similarity between a    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m query and a document more accurately than bi-encoders but are computationally expensive. A common pattern is to \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m retrieve 100 documents with fast vector search, then re-rank the top 10 with a cross-encoder [5].               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Semantic Routing**: Using a lightweight classifier to direct queries to the most appropriate specialized  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m index or RAG pipeline (e.g., routing technical queries to a documentation index vs. billing queries to a SQL    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m database).                                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Stochastic & Fairness Rankers**: New methods introduce \"stochastic rankers\" to prevent exposure bias      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m (where only the most popular docs are ever seen) and ensure diversity in the retrieved context [5].             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Sources                                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [1] Advanced & Modular RAG Patterns: https://ai-radar.aoe.com/architecture-pattern/rag/                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [2] GraphRAG Overview: https://microsoft.github.io/graphrag/                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [3] Agent Memory Systems (STM/LTM/Episodic):                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://www.linkedin.com/pulse/day-4-agent-memory-systems-short-term-long-term-episodic-marques-rp3ge           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [4] LLM Input Formatting & Sliding Windows:                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://milvus.io/ai-quick-reference/what-modifications-might-be-needed-to-the-llms-input-formatting-or-archite \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m cture-to-best-take-advantage-of-retrieved-documents-for-example-adding-special-tokens-or-segments-to-separate-c \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ontext                                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [5] Re-ranking & Dynamic Selection:                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://www.chitika.com/re-ranking-in-retrieval-augmented-generation-how-to-use-re-rankers-in-rag/              \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Research into context optimization reveals a multi-layered approach ranging from high-level architectural       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> strategies (summarization) to low-level token manipulation (pruning). Below is a summary of findings on         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> techniques for reducing context size and optimizing AI agent performance.                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 1. Summarization Techniques                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Summarization is the most common high-level strategy for managing long conversation histories.                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Rolling Summaries (Incremental Compression):** Instead of retaining the entire history, the system        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> periodically \"melts down\" previous turns into a concise summary. This maintains continuity but may lose         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> specific nuances over time [1].                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Hybrid Memory:** A robust approach that combines different memory types. It typically preserves \"pinned\"  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> key messages (like the system prompt or initial user instructions) verbatim while compressing intermediate      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> messages into summaries. This ensures critical instructions are never lost to compression artifacts [1].        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Externalized Memory:** For agents requiring long-term recall, context is offloaded to a vector database.  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Relevant information is retrieved semantically (RAG) rather than keeping everything in the active context       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> window [1].                                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 2. Prompt Compression Algorithms                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> These algorithms aim to reduce the number of tokens sent to the model without losing semantic meaning, often by <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> analyzing the information density of the text.                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Selective Context:** This method uses a smaller base language model (like GPT-2) to calculate the         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> \"self-information\" (perplexity) of lexical units (tokens, phrases, or sentences). Content with low              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> self-information—meaning it is predictable or redundant—is pruned. This can reduce context usage significantly  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> while maintaining performance on tasks like summarization and QA [2].                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **LLMLingua:** A coarse-to-fine compression framework. It employs a \"budget controller\" to dynamically      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> allocate different compression ratios to different parts of the prompt (e.g., compressing few-shot              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> demonstrations aggressively while preserving the user's specific instruction). It also aligns the distribution  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> between the small compression model and the target LLM to prevent performance degradation [3].                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 3. Token Selection &amp; Pruning Strategies                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Token pruning operates at a lower level, often during the inference process itself.                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Dynamic Token Pruning (e.g., LazyLLM):** Unlike static pruning which removes tokens once and for all,     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> dynamic strategies like LazyLLM selectively compute the Key-Value (KV) cache for tokens only when they are      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> important for the *next* token prediction. This allows the model to \"lazy load\" context, accelerating the       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> pre-filling stage and decoding without fine-tuning [4].                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Token Merging (ToMe):** While originally popular in Vision Transformers, similar concepts are applied to  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> LLMs where redundant tokens are merged rather than dropped, preserving their signal while reducing the sequence <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> length [3].                                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Dynamic Cutoff (Token Budgeting):** A simple LIFO (Last-In, First-Out) strategy where the oldest messages <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> are dropped once a strict token limit is reached. While easy to implement, it risks abrupt context loss [1].    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 4. Tools and Libraries                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Several libraries provide out-of-the-box implementations for these techniques.                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **LangChain:** Offers a suite of tools specifically for context optimization:                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     *   **Contextual Compression Retriever:** Wraps a base retriever and compresses the retrieved documents     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> before returning them.                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     *   **LLMChainExtractor:** Uses an LLM chain to extract *only* the relevant sentences from a retrieved      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> document, discarding irrelevant fluff.                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     *   **EmbeddingsFilter:** A cheaper/faster alternative that filters documents based on embedding similarity <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> thresholds rather than using an LLM call.                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     *   **DocumentCompressorPipeline:** Allows chaining multiple transformers (e.g., splitting text -&gt; removing <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> redundant documents -&gt; filtering by relevance) [5].                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> *   **Slimcontext:** A lightweight Node.js library designed for \"hybrid memory\" management. It automates the    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> process of preserving key messages while summarizing intermediate history to fit within a specific token budget <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [1].                                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Sources                                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [1] Don’t Let Your AI Agent Forget: Smarter Strategies for Summarizing Message History:                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://techwithibrahim.medium.com/dont-let-your-ai-agent-forget-smarter-strategies-for-summarizing-message-his <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> tory-a2d5284539f1                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [2] Selective Context GitHub Repository: https://github.com/liyucheng09/Selective_Context                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [3] LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models:                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://arxiv.org/html/2310.05736v2                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [4] LazyLLM: Dynamic Token Pruning for Efficient Long Context LLM Inference:                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://machinelearning.apple.com/research/dynamic-token-pruning                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [5] LangChain Contextual Compression Retriever:                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://lagnchain.readthedocs.io/en/latest/modules/indexes/retrievers/examples/contextual-compression.html      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Research into context optimization reveals a multi-layered approach ranging from high-level architectural       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m strategies (summarization) to low-level token manipulation (pruning). Below is a summary of findings on         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m techniques for reducing context size and optimizing AI agent performance.                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 1. Summarization Techniques                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Summarization is the most common high-level strategy for managing long conversation histories.                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Rolling Summaries (Incremental Compression):** Instead of retaining the entire history, the system        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m periodically \"melts down\" previous turns into a concise summary. This maintains continuity but may lose         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m specific nuances over time [1].                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Hybrid Memory:** A robust approach that combines different memory types. It typically preserves \"pinned\"  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m key messages (like the system prompt or initial user instructions) verbatim while compressing intermediate      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m messages into summaries. This ensures critical instructions are never lost to compression artifacts [1].        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Externalized Memory:** For agents requiring long-term recall, context is offloaded to a vector database.  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Relevant information is retrieved semantically (RAG) rather than keeping everything in the active context       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m window [1].                                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 2. Prompt Compression Algorithms                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m These algorithms aim to reduce the number of tokens sent to the model without losing semantic meaning, often by \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m analyzing the information density of the text.                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Selective Context:** This method uses a smaller base language model (like GPT-2) to calculate the         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m \"self-information\" (perplexity) of lexical units (tokens, phrases, or sentences). Content with low              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m self-information—meaning it is predictable or redundant—is pruned. This can reduce context usage significantly  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m while maintaining performance on tasks like summarization and QA [2].                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **LLMLingua:** A coarse-to-fine compression framework. It employs a \"budget controller\" to dynamically      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m allocate different compression ratios to different parts of the prompt (e.g., compressing few-shot              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m demonstrations aggressively while preserving the user's specific instruction). It also aligns the distribution  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m between the small compression model and the target LLM to prevent performance degradation [3].                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 3. Token Selection & Pruning Strategies                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Token pruning operates at a lower level, often during the inference process itself.                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Dynamic Token Pruning (e.g., LazyLLM):** Unlike static pruning which removes tokens once and for all,     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m dynamic strategies like LazyLLM selectively compute the Key-Value (KV) cache for tokens only when they are      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m important for the *next* token prediction. This allows the model to \"lazy load\" context, accelerating the       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m pre-filling stage and decoding without fine-tuning [4].                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Token Merging (ToMe):** While originally popular in Vision Transformers, similar concepts are applied to  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m LLMs where redundant tokens are merged rather than dropped, preserving their signal while reducing the sequence \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m length [3].                                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Dynamic Cutoff (Token Budgeting):** A simple LIFO (Last-In, First-Out) strategy where the oldest messages \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m are dropped once a strict token limit is reached. While easy to implement, it risks abrupt context loss [1].    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 4. Tools and Libraries                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Several libraries provide out-of-the-box implementations for these techniques.                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **LangChain:** Offers a suite of tools specifically for context optimization:                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     *   **Contextual Compression Retriever:** Wraps a base retriever and compresses the retrieved documents     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m before returning them.                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     *   **LLMChainExtractor:** Uses an LLM chain to extract *only* the relevant sentences from a retrieved      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m document, discarding irrelevant fluff.                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     *   **EmbeddingsFilter:** A cheaper/faster alternative that filters documents based on embedding similarity \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m thresholds rather than using an LLM call.                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     *   **DocumentCompressorPipeline:** Allows chaining multiple transformers (e.g., splitting text -> removing \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m redundant documents -> filtering by relevance) [5].                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m *   **Slimcontext:** A lightweight Node.js library designed for \"hybrid memory\" management. It automates the    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m process of preserving key messages while summarizing intermediate history to fit within a specific token budget \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [1].                                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Sources                                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [1] Don’t Let Your AI Agent Forget: Smarter Strategies for Summarizing Message History:                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://techwithibrahim.medium.com/dont-let-your-ai-agent-forget-smarter-strategies-for-summarizing-message-his \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m tory-a2d5284539f1                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [2] Selective Context GitHub Repository: https://github.com/liyucheng09/Selective_Context                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [3] LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models:                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://arxiv.org/html/2310.05736v2                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [4] LazyLLM: Dynamic Token Pruning for Efficient Long Context LLM Inference:                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://machinelearning.apple.com/research/dynamic-token-pruning                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [5] LangChain Contextual Compression Retriever:                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://lagnchain.readthedocs.io/en/latest/modules/indexes/retrievers/examples/contextual-compression.html      \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: write_file                                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"content\": \"# Context Engineering Approaches for Building AI Agents\\n\\nContext Engineering is the systematic  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> practice of designing, curating, and managing the information state (context) provided to an AI agent. Unlike   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> prompt engineering, which focuses on crafting static instructions, context engineering is an architectural      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> discipline concerned with the dynamic flow of information\\u2014history, tools, and data\\u2014to ensure agent    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> reliability over long-horizon tasks.\\n\\n## Core Principles\\n\\nEffective context engineering aims to solve       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> \\\"context rot\\\" and attention scarcity by optimizing the signal-to-noise ratio within the agent's limited       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context window.\\n\\n*   **Dynamic State Management**: Moving beyond static prompts to dynamic environments where <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context is retrieved, pruned, and updated in real-time [1].\\n*   **Signal Maximization**: Prioritizing          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> high-value tokens. As context length increases, a model's ability to retrieve specific details decreases; thus, <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> reducing noise is critical for accuracy [2].\\n*   **Distinction from Prompt Engineering**:\\n    *   *Prompt     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Engineering*: \\\"How do I ask this question to get the best answer?\\\"\\n    *   *Context Engineering*: \\\"How do I <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> architect the agent's memory and environment so it has the right information to answer any question?\\\"          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [1].\\n\\n## Structural Approaches\\n\\n### 1. Retrieval-Augmented Generation (RAG) Patterns\\nModern agents use     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> advanced RAG patterns to inject context dynamically rather than stuffing the window.\\n*   **Agentic RAG**: A    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> multi-step process where the agent actively critiques retrieved data and iteratively queries until it has       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> sufficient context, rather than accepting the first retrieval result [3].\\n*   **GraphRAG**: Uses knowledge     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> graphs to structure data hierarchically. This allows agents to answer \\\"global\\\" questions (e.g., \\\"What are    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> the main themes in this dataset?\\\") by traversing community summaries, a capability often missing in standard   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> vector search [4].\\n*   **Modular RAG**: Incorporates pre-retrieval steps (query rewriting/expansion) and       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> post-retrieval steps (re-ranking/pruning) to refine the context before it reaches the LLM [3].\\n\\n### 2. Memory <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Architectures\\nTo handle long-running tasks, agents employ split-memory architectures mimicking human           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> cognition.\\n*   **MemGPT Pattern**: Treats the LLM as an operating system that manages its own memory           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> hierarchy. It explicitly moves information between \\\"active context\\\" (RAM) and \\\"archival storage\\\"            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> (Disk/Vector DB) to manage limited context windows autonomously [5].\\n*   **Short-Term vs. Long-Term**:\\n    *  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> *Short-Term (STM)*: The immediate context window, often managed with sliding windows or rolling summaries.\\n    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> *   *Long-Term (LTM)*: Vector databases (semantic recall) and SQL databases (structured recall) for infinite    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> storage [5].\\n*   **Episodic Memory**: Storing sequences of past actions and results to enable few-shot         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> learning from previous experiences.\\n\\n### 3. Context Management Strategies\\n*   **Sliding Windows**: Breaking  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> long documents into overlapping chunks (e.g., 512 tokens with 128-token overlap) to process streams of data     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> without losing boundary context [6].\\n*   **Hierarchical Context (Fusion-in-Decoder)**: Processing documents at <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> multiple levels of abstraction. Agents first scan high-level summaries and only expand relevant sections into   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> full text [4].\\n\\n## Optimization &amp; Compression Techniques\\n\\nAs context windows fill, performance degrades and <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> costs rise. Optimization techniques aim to compress information without losing semantic value.\\n\\n### 1.        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Summarization Strategies\\n*   **Rolling Summaries**: Periodically \\\"melting down\\\" the conversation history     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> into a concise narrative. This frees up space but risks losing specific details over time [7].\\n*   **Hybrid    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Memory**: A robust approach that keeps \\\"pinned\\\" messages (system prompts, user instructions) verbatim while   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> compressing intermediate conversation turns. This prevents critical instructions from being distorted by        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> summarization artifacts [7].\\n\\n### 2. Algorithmic Compression\\n*   **Selective Context**: Uses a smaller       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> language model (like GPT-2) to calculate the \\\"self-information\\\" (perplexity) of tokens. Predictable or        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> redundant tokens are pruned, retaining only high-information content [8].\\n*   **LLMLingua**: A coarse-to-fine  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> compression framework that uses a budget controller to allocate compression ratios dynamically. It creates a    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> compressed prompt that retains the original instruction's intent while reducing token count by up to 20x        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [9].\\n\\n### 3. Dynamic Token Pruning\\n*   **LazyLLM**: A specialized inference technique that selectively       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> computes the Key-Value (KV) cache only for tokens important for the *next* token prediction. This allows the    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> model to \\\"lazy load\\\" context, speeding up processing for long contexts [10].\\n\\n## Implementation Tools\\n*    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> **LangChain**: Provides `ContextualCompressionRetriever` and `LLMChainExtractor` to automatically filter and    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> compress documents before they enter the agent's context [11].\\n*   **Slimcontext**: A lightweight library for  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> managing hybrid memory (pinned + summarized) in Node.js agents [7].\\n\\n### Sources\\n[1] HowAIWorks.ai,          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> \\\"Context Engineering: AI Agent Optimization Guide,\\\" Oct 2025.\\n[2] Anthropic Engineering, \\\"Effective context <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> engineering for AI agents.\\\"\\n[3] Advanced &amp; Modular RAG Patterns:                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://ai-radar.aoe.com/architecture-pattern/rag/\\n[4] GraphRAG Overview:                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://microsoft.github.io/graphrag/\\n[5] Agent Memory Systems:                                                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://www.linkedin.com/pulse/day-4-agent-memory-systems-short-term-long-term-episodic-marques-rp3ge\\n[6] LLM  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Input Formatting &amp; Sliding Windows: https://milvus.io/ai-quick-reference/\\n[7] Don\\u2019t Let Your AI Agent     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Forget:                                                                                                         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://techwithibrahim.medium.com/dont-let-your-ai-agent-forget-smarter-strategies-for-summarizing-message-his <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> tory-a2d5284539f1\\n[8] Selective Context: https://github.com/liyucheng09/Selective_Context\\n[9] LLMLingua:      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://arxiv.org/html/2310.05736v2\\n[10] LazyLLM:                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://machinelearning.apple.com/research/dynamic-token-pruning\\n[11] LangChain Contextual Compression:        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://lagnchain.readthedocs.io/en/latest/modules/indexes/retrievers/examples/contextual-compression.html\",    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"file_path\": \"/final_report.md\"                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: 75657a73-9ad8-4815-96b4-615298b4ac95                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: write_file                                                                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"content\": \"# Context Engineering Approaches for Building AI Agents\\n\\nContext Engineering is the systematic  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m practice of designing, curating, and managing the information state (context) provided to an AI agent. Unlike   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m prompt engineering, which focuses on crafting static instructions, context engineering is an architectural      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m discipline concerned with the dynamic flow of information\\u2014history, tools, and data\\u2014to ensure agent    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m reliability over long-horizon tasks.\\n\\n## Core Principles\\n\\nEffective context engineering aims to solve       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m \\\"context rot\\\" and attention scarcity by optimizing the signal-to-noise ratio within the agent's limited       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context window.\\n\\n*   **Dynamic State Management**: Moving beyond static prompts to dynamic environments where \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context is retrieved, pruned, and updated in real-time [1].\\n*   **Signal Maximization**: Prioritizing          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m high-value tokens. As context length increases, a model's ability to retrieve specific details decreases; thus, \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m reducing noise is critical for accuracy [2].\\n*   **Distinction from Prompt Engineering**:\\n    *   *Prompt     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Engineering*: \\\"How do I ask this question to get the best answer?\\\"\\n    *   *Context Engineering*: \\\"How do I \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m architect the agent's memory and environment so it has the right information to answer any question?\\\"          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [1].\\n\\n## Structural Approaches\\n\\n### 1. Retrieval-Augmented Generation (RAG) Patterns\\nModern agents use     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m advanced RAG patterns to inject context dynamically rather than stuffing the window.\\n*   **Agentic RAG**: A    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m multi-step process where the agent actively critiques retrieved data and iteratively queries until it has       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m sufficient context, rather than accepting the first retrieval result [3].\\n*   **GraphRAG**: Uses knowledge     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m graphs to structure data hierarchically. This allows agents to answer \\\"global\\\" questions (e.g., \\\"What are    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m the main themes in this dataset?\\\") by traversing community summaries, a capability often missing in standard   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m vector search [4].\\n*   **Modular RAG**: Incorporates pre-retrieval steps (query rewriting/expansion) and       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m post-retrieval steps (re-ranking/pruning) to refine the context before it reaches the LLM [3].\\n\\n### 2. Memory \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Architectures\\nTo handle long-running tasks, agents employ split-memory architectures mimicking human           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m cognition.\\n*   **MemGPT Pattern**: Treats the LLM as an operating system that manages its own memory           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m hierarchy. It explicitly moves information between \\\"active context\\\" (RAM) and \\\"archival storage\\\"            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m (Disk/Vector DB) to manage limited context windows autonomously [5].\\n*   **Short-Term vs. Long-Term**:\\n    *  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m *Short-Term (STM)*: The immediate context window, often managed with sliding windows or rolling summaries.\\n    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m *   *Long-Term (LTM)*: Vector databases (semantic recall) and SQL databases (structured recall) for infinite    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m storage [5].\\n*   **Episodic Memory**: Storing sequences of past actions and results to enable few-shot         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m learning from previous experiences.\\n\\n### 3. Context Management Strategies\\n*   **Sliding Windows**: Breaking  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m long documents into overlapping chunks (e.g., 512 tokens with 128-token overlap) to process streams of data     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m without losing boundary context [6].\\n*   **Hierarchical Context (Fusion-in-Decoder)**: Processing documents at \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m multiple levels of abstraction. Agents first scan high-level summaries and only expand relevant sections into   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m full text [4].\\n\\n## Optimization & Compression Techniques\\n\\nAs context windows fill, performance degrades and \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m costs rise. Optimization techniques aim to compress information without losing semantic value.\\n\\n### 1.        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Summarization Strategies\\n*   **Rolling Summaries**: Periodically \\\"melting down\\\" the conversation history     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m into a concise narrative. This frees up space but risks losing specific details over time [7].\\n*   **Hybrid    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Memory**: A robust approach that keeps \\\"pinned\\\" messages (system prompts, user instructions) verbatim while   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m compressing intermediate conversation turns. This prevents critical instructions from being distorted by        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m summarization artifacts [7].\\n\\n### 2. Algorithmic Compression\\n*   **Selective Context**: Uses a smaller       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m language model (like GPT-2) to calculate the \\\"self-information\\\" (perplexity) of tokens. Predictable or        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m redundant tokens are pruned, retaining only high-information content [8].\\n*   **LLMLingua**: A coarse-to-fine  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m compression framework that uses a budget controller to allocate compression ratios dynamically. It creates a    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m compressed prompt that retains the original instruction's intent while reducing token count by up to 20x        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [9].\\n\\n### 3. Dynamic Token Pruning\\n*   **LazyLLM**: A specialized inference technique that selectively       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m computes the Key-Value (KV) cache only for tokens important for the *next* token prediction. This allows the    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m model to \\\"lazy load\\\" context, speeding up processing for long contexts [10].\\n\\n## Implementation Tools\\n*    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m **LangChain**: Provides `ContextualCompressionRetriever` and `LLMChainExtractor` to automatically filter and    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m compress documents before they enter the agent's context [11].\\n*   **Slimcontext**: A lightweight library for  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m managing hybrid memory (pinned + summarized) in Node.js agents [7].\\n\\n### Sources\\n[1] HowAIWorks.ai,          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m \\\"Context Engineering: AI Agent Optimization Guide,\\\" Oct 2025.\\n[2] Anthropic Engineering, \\\"Effective context \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m engineering for AI agents.\\\"\\n[3] Advanced & Modular RAG Patterns:                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://ai-radar.aoe.com/architecture-pattern/rag/\\n[4] GraphRAG Overview:                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://microsoft.github.io/graphrag/\\n[5] Agent Memory Systems:                                                \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://www.linkedin.com/pulse/day-4-agent-memory-systems-short-term-long-term-episodic-marques-rp3ge\\n[6] LLM  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Input Formatting & Sliding Windows: https://milvus.io/ai-quick-reference/\\n[7] Don\\u2019t Let Your AI Agent     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Forget:                                                                                                         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://techwithibrahim.medium.com/dont-let-your-ai-agent-forget-smarter-strategies-for-summarizing-message-his \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m tory-a2d5284539f1\\n[8] Selective Context: https://github.com/liyucheng09/Selective_Context\\n[9] LLMLingua:      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://arxiv.org/html/2310.05736v2\\n[10] LazyLLM:                                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://machinelearning.apple.com/research/dynamic-token-pruning\\n[11] LangChain Contextual Compression:        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://lagnchain.readthedocs.io/en/latest/modules/indexes/retrievers/examples/contextual-compression.html\",    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"file_path\": \"/final_report.md\"                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: 75657a73-9ad8-4815-96b4-615298b4ac95                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Updated file /final_report.md                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Updated file /final_report.md                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: write_todos                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"todos\": [                                                                                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research core concepts and definitions of context engineering in AI agents\",                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research structural techniques for context management (e.g., RAG, Long-term memory systems,   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Sliding windows)\",                                                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research context optimization and compression techniques (e.g., Prompt compression,           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Summarization, Token selection)\",                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Write final report on context engineering approaches\",                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     }                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   ]                                                                                                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: 41f5ec4f-9cc1-42e5-bfe5-578e82689f9d                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: write_todos                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"todos\": [                                                                                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research core concepts and definitions of context engineering in AI agents\",                  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research structural techniques for context management (e.g., RAG, Long-term memory systems,   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Sliding windows)\",                                                                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research context optimization and compression techniques (e.g., Prompt compression,           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Summarization, Token selection)\",                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Write final report on context engineering approaches\",                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     }                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   ]                                                                                                             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: 41f5ec4f-9cc1-42e5-bfe5-578e82689f9d                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Updated todo list to [{'content': 'Research core concepts and definitions of context engineering in AI agents', <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 'status': 'completed'}, {'content': 'Research structural techniques for context management (e.g., RAG,          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Long-term memory systems, Sliding windows)', 'status': 'completed'}, {'content': 'Research context optimization <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> and compression techniques (e.g., Prompt compression, Summarization, Token selection)', 'status': 'completed'}, <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> {'content': 'Write final report on context engineering approaches', 'status': 'completed'}]                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Updated todo list to [{'content': 'Research core concepts and definitions of context engineering in AI agents', \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 'status': 'completed'}, {'content': 'Research structural techniques for context management (e.g., RAG,          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Long-term memory systems, Sliding windows)', 'status': 'completed'}, {'content': 'Research context optimization \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m and compression techniques (e.g., Prompt compression, Summarization, Token selection)', 'status': 'completed'}, \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m {'content': 'Write final report on context engineering approaches', 'status': 'completed'}]                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> The research on context engineering approaches for AI agents is complete. I have compiled a detailed report     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> covering core principles, structural architectures (like RAG and Memory Systems), and optimization techniques   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> (such as compression and pruning).                                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> ### Key Findings                                                                                                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> *   **Definition**: Context engineering is the architectural practice of managing the agent's information       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> environment (history, tools, data) to ensure reliability, as opposed to just crafting static prompts.           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> *   **Structural Techniques**:                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     *   **RAG Patterns**: GraphRAG and Agentic RAG allow for dynamic and hierarchical information retrieval.    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     *   **Memory**: \"MemGPT\" style architectures that manage Short-Term vs. Long-Term memory autonomously.      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> *   **Optimization**:                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     *   **Compression**: Algorithms like **LLMLingua** and **Selective Context** to reduce token usage while    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> preserving meaning.                                                                                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     *   **Summarization**: \"Rolling summaries\" and \"Hybrid memory\" to balance history retention with context    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> limits.                                                                                                         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> The full report has been saved to `/final_report.md`.                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> ### Sources                                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [1] HowAIWorks.ai, \"Context Engineering: AI Agent Optimization Guide,\" Oct 2025.                                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [2] Advanced &amp; Modular RAG Patterns: https://ai-radar.aoe.com/architecture-pattern/rag/                         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [3] LLMLingua: https://arxiv.org/html/2310.05736v2                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [4] GraphRAG Overview: https://microsoft.github.io/graphrag/                                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m The research on context engineering approaches for AI agents is complete. I have compiled a detailed report     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m covering core principles, structural architectures (like RAG and Memory Systems), and optimization techniques   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m (such as compression and pruning).                                                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m ### Key Findings                                                                                                \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m *   **Definition**: Context engineering is the architectural practice of managing the agent's information       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m environment (history, tools, data) to ensure reliability, as opposed to just crafting static prompts.           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m *   **Structural Techniques**:                                                                                  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     *   **RAG Patterns**: GraphRAG and Agentic RAG allow for dynamic and hierarchical information retrieval.    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     *   **Memory**: \"MemGPT\" style architectures that manage Short-Term vs. Long-Term memory autonomously.      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m *   **Optimization**:                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     *   **Compression**: Algorithms like **LLMLingua** and **Selective Context** to reduce token usage while    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m preserving meaning.                                                                                             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     *   **Summarization**: \"Rolling summaries\" and \"Hybrid memory\" to balance history retention with context    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m limits.                                                                                                         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m The full report has been saved to `/final_report.md`.                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m ### Sources                                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [1] HowAIWorks.ai, \"Context Engineering: AI Agent Optimization Guide,\" Oct 2025.                                \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [2] Advanced & Modular RAG Patterns: https://ai-radar.aoe.com/architecture-pattern/rag/                         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [3] LLMLingua: https://arxiv.org/html/2310.05736v2                                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [4] GraphRAG Overview: https://microsoft.github.io/graphrag/                                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"research context engineering approaches used to build AI agents\",\n",
    "            }\n",
    "        ],\n",
    "    }, \n",
    ")\n",
    "\n",
    "format_messages(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "188b5ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  # Context Engineering Approaches for Building AI Agents                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context Engineering is the systematic practice of designing, curating, and managing the information state      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  (context) provided to an AI agent. Unlike prompt engineering, which focuses on crafting static instructions,   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  context engineering is an architectural discipline concerned with the dynamic flow of information—history,     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  tools, and data—to ensure agent reliability over long-horizon tasks.                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Core Principles</span>                                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Effective context engineering aims to solve \"context rot\" and attention scarcity by optimizing the             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  signal-to-noise ratio within the agent's limited context window.                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Dynamic State Management**: Moving beyond static prompts to dynamic environments where context is        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  retrieved, pruned, and updated in real-time [1].                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Signal Maximization**: Prioritizing high-value tokens. As context length increases, a model's ability    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  to retrieve specific details decreases; thus, reducing noise is critical for accuracy [2].                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Distinction from Prompt Engineering**:                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>      *   *Prompt Engineering*: \"How do I ask this question to get the best answer?\"                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>      *   *Context Engineering*: \"How do I architect the agent's memory and environment so it has the right      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  information to answer any question?\" [1].                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Structural Approaches</span>                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### 1. Retrieval-Augmented Generation (RAG) Patterns</span>                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Modern agents use advanced RAG patterns to inject context dynamically rather than stuffing the window.         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Agentic RAG**: A multi-step process where the agent actively critiques retrieved data and iteratively    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  queries until it has sufficient context, rather than accepting the first retrieval result [3].                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **GraphRAG**: Uses knowledge graphs to structure data hierarchically. This allows agents to answer         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"global\" questions (e.g., \"What are the main themes in this dataset?\") by traversing community summaries, a    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  capability often missing in standard vector search [4].                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Modular RAG**: Incorporates pre-retrieval steps (query rewriting/expansion) and post-retrieval steps     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  (re-ranking/pruning) to refine the context before it reaches the LLM [3].                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### 2. Memory Architectures</span>                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  To handle long-running tasks, agents employ split-memory architectures mimicking human cognition.              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **MemGPT Pattern**: Treats the LLM as an operating system that manages its own memory hierarchy. It        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  explicitly moves information between \"active context\" (RAM) and \"archival storage\" (Disk/Vector DB) to manage  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  limited context windows autonomously [5].                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Short-Term vs. Long-Term**:                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>      *   *Short-Term (STM)*: The immediate context window, often managed with sliding windows or rolling        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  summaries.                                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>      *   *Long-Term (LTM)*: Vector databases (semantic recall) and SQL databases (structured recall) for        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  infinite storage [5].                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Episodic Memory**: Storing sequences of past actions and results to enable few-shot learning from        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  previous experiences.                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### 3. Context Management Strategies</span>                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Sliding Windows**: Breaking long documents into overlapping chunks (e.g., 512 tokens with 128-token      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  overlap) to process streams of data without losing boundary context [6].                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Hierarchical Context (Fusion-in-Decoder)**: Processing documents at multiple levels of abstraction.      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Agents first scan high-level summaries and only expand relevant sections into full text [4].                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Optimization &amp; Compression Techniques</span>                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  As context windows fill, performance degrades and costs rise. Optimization techniques aim to compress          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  information without losing semantic value.                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### 1. Summarization Strategies</span>                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Rolling Summaries**: Periodically \"melting down\" the conversation history into a concise narrative.      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  This frees up space but risks losing specific details over time [7].                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Hybrid Memory**: A robust approach that keeps \"pinned\" messages (system prompts, user instructions)      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  verbatim while compressing intermediate conversation turns. This prevents critical instructions from being     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  distorted by summarization artifacts [7].                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### 2. Algorithmic Compression</span>                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Selective Context**: Uses a smaller language model (like GPT-2) to calculate the \"self-information\"      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  (perplexity) of tokens. Predictable or redundant tokens are pruned, retaining only high-information content    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [8].                                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **LLMLingua**: A coarse-to-fine compression framework that uses a budget controller to allocate            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  compression ratios dynamically. It creates a compressed prompt that retains the original instruction's intent  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  while reducing token count by up to 20x [9].                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### 3. Dynamic Token Pruning</span>                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **LazyLLM**: A specialized inference technique that selectively computes the Key-Value (KV) cache only     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  for tokens important for the *next* token prediction. This allows the model to \"lazy load\" context, speeding   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  up processing for long contexts [10].                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Implementation Tools</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **LangChain**: Provides `ContextualCompressionRetriever` and `LLMChainExtractor` to automatically filter   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  and compress documents before they enter the agent's context [11].                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  *   **Slimcontext**: A lightweight library for managing hybrid memory (pinned + summarized) in Node.js agents  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [7].                                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Sources</span>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [1] HowAIWorks.ai, \"Context Engineering: AI Agent Optimization Guide,\" Oct 2025.                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [2] Anthropic Engineering, \"Effective context engineering for AI agents.\"                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [3] Advanced &amp; Modular RAG Patterns: https://ai-radar.aoe.com/architecture-pattern/rag/                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [4] GraphRAG Overview: https://microsoft.github.io/graphrag/                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [5] Agent Memory Systems:                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  https://www.linkedin.com/pulse/day-4-agent-memory-systems-short-term-long-term-episodic-marques-rp3ge          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [6] LLM Input Formatting &amp; Sliding Windows: https://milvus.io/ai-quick-reference/                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [7] Don’t Let Your AI Agent Forget:                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  https://techwithibrahim.medium.com/dont-let-your-ai-agent-forget-smarter-strategies-for-summarizing-message-h  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  istory-a2d5284539f1                                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [8] Selective Context: https://github.com/liyucheng09/Selective_Context                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [9] LLMLingua: https://arxiv.org/html/2310.05736v2                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [10] LazyLLM: https://machinelearning.apple.com/research/dynamic-token-pruning                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [11] LangChain Contextual Compression:                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  https://lagnchain.readthedocs.io/en/latest/modules/indexes/retrievers/examples/contextual-compression.html     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  # Context Engineering Approaches for Building AI Agents                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context Engineering is the systematic practice of designing, curating, and managing the information state      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  (context) provided to an AI agent. Unlike prompt engineering, which focuses on crafting static instructions,   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  context engineering is an architectural discipline concerned with the dynamic flow of information—history,     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  tools, and data—to ensure agent reliability over long-horizon tasks.                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Core Principles\u001b[0m                                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Effective context engineering aims to solve \"context rot\" and attention scarcity by optimizing the             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  signal-to-noise ratio within the agent's limited context window.                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Dynamic State Management**: Moving beyond static prompts to dynamic environments where context is        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  retrieved, pruned, and updated in real-time [1].                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Signal Maximization**: Prioritizing high-value tokens. As context length increases, a model's ability    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  to retrieve specific details decreases; thus, reducing noise is critical for accuracy [2].                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Distinction from Prompt Engineering**:                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m      *   *Prompt Engineering*: \"How do I ask this question to get the best answer?\"                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m      *   *Context Engineering*: \"How do I architect the agent's memory and environment so it has the right      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  information to answer any question?\" [1].                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Structural Approaches\u001b[0m                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## 1. Retrieval-Augmented Generation (RAG) Patterns\u001b[0m                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Modern agents use advanced RAG patterns to inject context dynamically rather than stuffing the window.         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Agentic RAG**: A multi-step process where the agent actively critiques retrieved data and iteratively    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  queries until it has sufficient context, rather than accepting the first retrieval result [3].                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **GraphRAG**: Uses knowledge graphs to structure data hierarchically. This allows agents to answer         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"global\" questions (e.g., \"What are the main themes in this dataset?\") by traversing community summaries, a    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  capability often missing in standard vector search [4].                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Modular RAG**: Incorporates pre-retrieval steps (query rewriting/expansion) and post-retrieval steps     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  (re-ranking/pruning) to refine the context before it reaches the LLM [3].                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## 2. Memory Architectures\u001b[0m                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  To handle long-running tasks, agents employ split-memory architectures mimicking human cognition.              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **MemGPT Pattern**: Treats the LLM as an operating system that manages its own memory hierarchy. It        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  explicitly moves information between \"active context\" (RAM) and \"archival storage\" (Disk/Vector DB) to manage  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  limited context windows autonomously [5].                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Short-Term vs. Long-Term**:                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m      *   *Short-Term (STM)*: The immediate context window, often managed with sliding windows or rolling        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  summaries.                                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m      *   *Long-Term (LTM)*: Vector databases (semantic recall) and SQL databases (structured recall) for        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  infinite storage [5].                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Episodic Memory**: Storing sequences of past actions and results to enable few-shot learning from        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  previous experiences.                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## 3. Context Management Strategies\u001b[0m                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Sliding Windows**: Breaking long documents into overlapping chunks (e.g., 512 tokens with 128-token      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  overlap) to process streams of data without losing boundary context [6].                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Hierarchical Context (Fusion-in-Decoder)**: Processing documents at multiple levels of abstraction.      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Agents first scan high-level summaries and only expand relevant sections into full text [4].                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Optimization & Compression Techniques\u001b[0m                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  As context windows fill, performance degrades and costs rise. Optimization techniques aim to compress          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  information without losing semantic value.                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## 1. Summarization Strategies\u001b[0m                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Rolling Summaries**: Periodically \"melting down\" the conversation history into a concise narrative.      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  This frees up space but risks losing specific details over time [7].                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Hybrid Memory**: A robust approach that keeps \"pinned\" messages (system prompts, user instructions)      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  verbatim while compressing intermediate conversation turns. This prevents critical instructions from being     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  distorted by summarization artifacts [7].                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## 2. Algorithmic Compression\u001b[0m                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Selective Context**: Uses a smaller language model (like GPT-2) to calculate the \"self-information\"      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  (perplexity) of tokens. Predictable or redundant tokens are pruned, retaining only high-information content    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [8].                                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **LLMLingua**: A coarse-to-fine compression framework that uses a budget controller to allocate            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  compression ratios dynamically. It creates a compressed prompt that retains the original instruction's intent  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  while reducing token count by up to 20x [9].                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## 3. Dynamic Token Pruning\u001b[0m                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **LazyLLM**: A specialized inference technique that selectively computes the Key-Value (KV) cache only     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  for tokens important for the *next* token prediction. This allows the model to \"lazy load\" context, speeding   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  up processing for long contexts [10].                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Implementation Tools\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **LangChain**: Provides `ContextualCompressionRetriever` and `LLMChainExtractor` to automatically filter   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  and compress documents before they enter the agent's context [11].                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  *   **Slimcontext**: A lightweight library for managing hybrid memory (pinned + summarized) in Node.js agents  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [7].                                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Sources\u001b[0m                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [1] HowAIWorks.ai, \"Context Engineering: AI Agent Optimization Guide,\" Oct 2025.                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [2] Anthropic Engineering, \"Effective context engineering for AI agents.\"                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [3] Advanced & Modular RAG Patterns: https://ai-radar.aoe.com/architecture-pattern/rag/                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [4] GraphRAG Overview: https://microsoft.github.io/graphrag/                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [5] Agent Memory Systems:                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  https://www.linkedin.com/pulse/day-4-agent-memory-systems-short-term-long-term-episodic-marques-rp3ge          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [6] LLM Input Formatting & Sliding Windows: https://milvus.io/ai-quick-reference/                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [7] Don’t Let Your AI Agent Forget:                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  https://techwithibrahim.medium.com/dont-let-your-ai-agent-forget-smarter-strategies-for-summarizing-message-h  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  istory-a2d5284539f1                                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [8] Selective Context: https://github.com/liyucheng09/Selective_Context                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [9] LLMLingua: https://arxiv.org/html/2310.05736v2                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [10] LazyLLM: https://machinelearning.apple.com/research/dynamic-token-pruning                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [11] LangChain Contextual Compression:                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  https://lagnchain.readthedocs.io/en/latest/modules/indexes/retrievers/examples/contextual-compression.html     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepagents.backends.utils import file_data_to_string\n",
    "\n",
    "# Convert a specific file to string\n",
    "file_content = file_data_to_string(result[\"files\"]['/final_report.md'])\n",
    "show_prompt(file_content) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc6784",
   "metadata": {},
   "source": [
    "Trace: \n",
    "\n",
    "https://smith.langchain.com/public/34012df8-ffe1-424b-aa17-efb21e87c53e/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d73925c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
